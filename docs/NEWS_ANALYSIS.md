# 뉴스 감성 분석 시스템 기술 문서

> Korean Stocks AI/ML Analysis System `v0.2.9`
> 최종 업데이트: 2026-02-28

---

## 목차

1. [개요](#1-개요)
2. [수집 단계](#2-수집-단계)
3. [전처리](#3-전처리)
4. [감성 분석](#4-감성-분석)
5. [캐시 구조](#5-캐시-구조)
6. [점수 반영](#6-점수-반영)
7. [설계 원칙 및 한계](#7-설계-원칙-및-한계)

---

## 1. 개요

뉴스 감성 분석은 기술적 지표(tech_score)·ML 예측(ml_score)과 함께 종합 점수(composite)를 구성하는 세 번째 축이다.
주요 담당 클래스: `src/koreanstocks/core/engine/news_agent.py` → `NewsAgent`

```
수집 (Naver News + DART 공시)
  → 전처리 (계열사 필터 + 중복 제거 + 시간 가중치)
  → GPT-4o-mini 감성 분석
  → sentiment_score (-100 ~ 100)
  → composite 가중 반영 (25%)
```

---

## 2. 수집 단계

### 2-1. 네이버 뉴스 API

| 항목 | 값 |
|------|-----|
| 엔드포인트 | `openapi.naver.com/v1/search/news.json` |
| 검색어 | `"{종목명} 주가"` |
| 수집 수 | `display=50` (중복·계열사 제거 후 여유분 확보) |
| 정렬 | `sort=date` (최신순) |
| 수집 필드 | `title`, `link`, `originallink`, `pubDate`, `days_ago`, `days_ago_int` |

검색어에 **" 주가"** 를 추가해 동명 계열사 기사 혼입을 부분적으로 억제한다.
`days_ago` / `days_ago_int` 는 `pubDate` 파싱 결과로, 전처리 단계에서 시간 가중치 계산에 사용된다.

### 2-2. DART 공시 API (금감원 전자공시)

| 항목 | 값 |
|------|-----|
| corp_code 조회 | `opendart.fss.or.kr/api/corpCode.xml` (ZIP, 전체 기업 매핑) |
| 공시 목록 조회 | `opendart.fss.or.kr/api/list.json` |
| 수집 기간 | 최근 30일 |
| 수집 수 | `page_count=10` |

**종목코드 → corp_code 매핑 방식:**
`corpCode.xml` ZIP(전체 기업 목록)을 당일 1회 다운로드하여 `dart_corp_cache.json`(디스크)에 저장.
당일 재실행 시 디스크 캐시에서 즉시 로드 (ZIP 재다운로드 없음). 날짜 변경 시 자동 재수집.

**수집 공시 유형:**

| 코드 | 분류 | 예시 |
|------|------|------|
| A | 정기공시 | 분기·반기·사업보고서 |
| B | 주요사항 | 유상증자·전환사채·합병 |
| C | 발행공시 | 증권신고서 |
| D | 지분공시 | 최대주주·임원 지분 변동 |
| E | 기타공시 | 기타 |
| F | 외부감사 | 감사보고서 |
| I | 거래소공시 | 수주계약·자사주 취득 |

---

## 3. 전처리

전처리는 **계열사 필터 → 중복 제거** 순으로 적용된다.

### 3-1. 계열사 혼입 기사 필터 (`_filter_by_stock_name`)

"카카오 주가" 검색 시 카카오뱅크·카카오페이 기사가 섞이는 문제를 정규식 기반으로 해소한다.

**판단 기준:** 종목명 바로 뒤에 오는 문자가

| 경우 | 판단 | 예시 |
|------|------|------|
| 한글 조사 + 비한글 | 단독 언급 → **유지** | `카카오가 주가 상승` |
| 비한글(공백·숫자·영문 등) | 단독 언급 → **유지** | `카카오 주가` |
| 한글이 바로 이어짐 | 복합어(계열사명) → **제거** | `카카오뱅크 실적` |

조사 목록 (긴 형태 우선): `이고`, `이며`, `에서`, `로부터`, ... `가`, `는`, `을`, `를` 등 전체 적용.

**Fallback:** 필터 결과가 3건 미만이면 원본 반환 (소형주·짧은 종목명 방어).

### 3-2. 중복 기사 2단계 제거 (`_deduplicate_news`)

**1단계 — 도메인 중복 제거**

`originallink` URL의 도메인(netloc)을 기준으로, 같은 매체의 기사는 가장 최신 1건만 유지한다.
API가 최신순으로 반환하므로 첫 번째 항목이 자동으로 선택된다.

> 배경: 연합뉴스 원고 1건이 수십 개 매체에 동시 게재되는 패턴이 한국 뉴스 생태계에서 빈번하다.

**2단계 — 제목 Jaccard 유사도 중복 제거**

```python
jaccard = len(tokens_A & tokens_B) / len(tokens_A | tokens_B)
# jaccard > 0.75 이면 중복으로 판단하고 제거
```

한글·영문을 `[\s\W]+` 패턴으로 토큰화.
도메인이 달라도 사실상 동일한 내용의 기사를 추가로 걸러낸다.

### 3-3. 시간 가중치 (`_time_weight`)

Python에서 수치를 계산한 뒤 GPT 프롬프트에 직접 전달한다.
GPT에게 "오래된 뉴스는 덜 중요하게 봐라"고 텍스트로만 지시하는 것보다 숫자를 명시하는 것이 일관성이 높다.

**지수 감쇠 공식:**

```
w = exp(−0.35 × days)
```

| 경과 일수 | 가중치 |
|---------|-------|
| 오늘 (0일) | 1.00 |
| 1일 전 | 0.70 |
| 3일 전 | 0.35 |
| 7일 전 | 0.09 |
| 14일 전 | 0.01 |

GPT 프롬프트 예시:
```
- [가중치 1.00 / 오늘] 삼성전자 어닝서프라이즈…영업이익 시장 예상 상회
- [가중치 0.35 / 3일 전] 반도체 업황 회복 기대감에 외국인 순매수
- [가중치 0.09 / 7일 전] 美 기술주 약세에 동반 하락
```

---

## 4. 감성 분석

### 4-1. GPT 호출 구성

| 항목 | 값 |
|------|-----|
| 모델 | `gpt-4o-mini` (config.DEFAULT_MODEL) |
| temperature | 0.1 (일관된 점수 산출) |
| max_tokens | 200 |
| response_format | `{"type": "json_object"}` |

### 4-2. 프롬프트 구조

```
[뉴스 제목 및 시간 가중치]
- [가중치 {w} / {age}] {title}
...

[금감원 공식 공시 — 뉴스보다 직접적이고 신뢰도 높음]  ← DART 있을 때만
- [주요사항 / 2026-02-20] 주요사항보고서(유상증자결정)
...
공시 내용은 뉴스 헤드라인보다 주가 영향이 크므로 더 높은 비중을 두세요.
```

DART 공시는 별도 섹션으로 분리해 GPT가 뉴스 헤드라인보다 높은 신뢰도를 부여하도록 유도한다.

### 4-3. 출력 스키마

GPT가 반환하는 필드(4개) + Python이 추가하는 필드(1개)로 구성된다.

```json
{
  "sentiment_score": -45,
  "sentiment_label": "Bearish",
  "reason": "엔비디아 급락 여파로 반도체주 전반 약세, DART 공시 없음",
  "top_news": "美반도체주 약세에 삼성전자·SK하이닉스 하락 출발",
  "articles": [
    {"title": "美반도체주 약세에 삼성전자·SK하이닉스 하락 출발",
     "link": "https://...",
     "originallink": "https://...",
     "pubDate": "Thu, 27 Feb 2026 09:30:00 +0900",
     "days_ago": "오늘"}
  ]
}
```

| 필드 | 출처 | 범위 | 설명 |
|------|------|------|------|
| sentiment_score | GPT | -100 ~ 100 | 음수: 악재, 양수: 호재 |
| sentiment_label | GPT | Very Bullish / Bullish / Neutral / Bearish / Very Bearish | 구간 레이블 |
| reason | GPT | 한 문장 | 공시·고가중치 뉴스 위주 산출 근거 |
| top_news | GPT | 한 문장 | 가장 영향력 큰 단일 항목 요약 |
| articles | Python | 배열 | 수집·필터링된 뉴스 원본 목록 (`title`, `link`, `originallink`, `pubDate`, `days_ago`) |

> `articles` 필드는 GPT 응답 후 Python에서 직접 추가된다. 뉴스가 없을 때는 `[]` 빈 배열.

### 4-4. 점수 해석 기준

| 범위 | 레이블 | 의미 |
|------|--------|------|
| 51 ~ 100 | Very Bullish | 매우 긍정 (강한 호재 공시·뉴스) |
| 1 ~ 50 | Bullish | 긍정 |
| 0 | Neutral | 중립 또는 뉴스 없음 |
| -1 ~ -50 | Bearish | 부정 |
| -51 ~ -100 | Very Bearish | 매우 부정 (강한 악재 공시·뉴스) |

---

## 5. 캐시 구조

### 2단계 캐시 (L1 메모리 → L2 SQLite)

```
get_sentiment_score(stock_name, stock_code)
  │
  ├─ L1 히트?  →  반환 (프로세스 내 중복 호출)
  │
  ├─ L2 히트?  →  L1에 올리고 반환 (당일 재실행·앱 재시작)
  │
  └─ 미스
       ├─ Naver News 수집 + 계열사 필터 + 중복 제거
       ├─ DART 공시 수집
       ├─ GPT 감성 분석
       ├─ L1 저장
       └─ L2(SQLite) 저장
```

### 캐시 키

```
cache_key = "{종목명}_{YYYY-MM-DD}"
예: "삼성전자_2026-02-27"
```

날짜가 포함되어 별도 TTL 없이 자동 만료. 날짜가 바뀌면 자동으로 재수집.

### SQLite 테이블 (`sentiment_cache`)

```sql
CREATE TABLE sentiment_cache (
    cache_key   TEXT PRIMARY KEY,   -- "{종목명}_{날짜}"
    result_json TEXT NOT NULL,      -- JSON 직렬화된 분석 결과
    created_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

7일 이상 된 항목은 새 데이터 저장 시 자동 정리된다.

### GitHub Actions에서의 효과

| 상황 | 동작 |
|------|------|
| 당일 첫 실행 | L2 미스 → API·GPT 호출 → DB 저장 |
| 당일 재실행 | L2 히트 → API·GPT 비용 0 |
| 익일 실행 | 키 불일치 → 재수집 |
| 앱 재시작 (서버 재시작) | L1 초기화되지만 L2 히트 |

---

## 6. 점수 반영

```python
sentiment_norm = max(0.0, min(100.0, (sentiment_score + 100.0) / 2.0))
# -100 → 0,  0 → 50,  100 → 100

# ML 모델 활성 시
composite = tech_score * 0.40 + ml_score * 0.35 + sentiment_norm * 0.25

# ML 모델 없을 시 (fallback)
composite = tech_score * 0.65 + sentiment_norm * 0.35
```

감성 점수는 composite의 최대 25%를 차지한다.
뉴스 노이즈가 높은 특성을 감안해 tech·ML 대비 낮은 비중으로 고정.

---

## 7. 설계 원칙 및 한계

### 고정값 (임의 수정 금지)

| 항목 | 값 | 이유 |
|------|----|------|
| sentiment 가중치 | 25% (ML 있음), 35% (ML 없음) | 백테스트 검증 기반 |
| 시간 감쇠 계수 | λ = 0.35 | 1일 전 70%, 7일 전 9%로 적절한 감쇠 |
| Jaccard 임계값 | 0.75 | 낮추면 과잉 제거, 높이면 중복 잔존 |
| 계열사 필터 fallback | 3건 미만 | 소형주·짧은 종목명 방어 |

### 알려진 한계

| 항목 | 내용 | 영향도 |
|------|------|-------|
| 헤드라인 전용 분석 | 본문 없이 제목만 분석. 기대 대비 방향(어닝 서프라이즈 등) 판단 불가 | 높음 |
| 계열사·업종 오염 | 계열사 필터로 부분 해소. 조사 기반 정규식 오탐 가능 (짧은 종목명) | 낮음 (개선됨) |
| DART 공시 제목만 수집 | 유상증자 금액·비율 등 규모 정보 없음. 같은 유형도 영향도 차이 큼 | 중간 |
| 감성 점수 분산 작음 | GPT가 주로 -30~+30 범위 사용. 양극단 거의 출력 안 함 | 낮음 |
| corpCode 캐시 범위 | 디스크 캐시(`dart_corp_cache.json`)로 당일 재실행 시 ZIP 재다운로드 방지. 날짜 변경 시 자동 재수집 | 낮음 |

### 향후 개선 방향

| 우선순위 | 항목 | 기대 효과 |
|---------|------|---------|
| 1 | DART 주요사항(B) 공시 금액·비율 파싱 | 분석 정확도 향상 |
| 2 | 감성 점수 calibration — 분포 정규화로 전범위 활용 | 가중치 실효성 향상 |
| 3 | 본문 일부 수집 — 제목 외 첫 2문장 추가 분석 | 어닝서프라이즈 등 방향 판단 개선 |
